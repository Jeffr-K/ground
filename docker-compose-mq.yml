version: '3.8'

services:

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.2
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-log:/var/lib/zookeeper/log
    networks:
      - kafka-network
      - app-network
    healthcheck:
      test: echo srvr | nc zookeeper 2181 || exit 1
      interval: 30s
      timeout: 10s
      retries: 3

  kafka:
    image: confluentinc/cp-kafka:7.3.2
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - kafka-network
      - app-network
    healthcheck:
      test: kafka-topics --bootstrap-server kafka:29092 --list || exit 1
      interval: 30s
      timeout: 10s
      retries: 5

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
      - kafka-connect
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: connect
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
    networks:
      - kafka-network
      - app-network

  kafka-connect:
    image: debezium/connect:2.3
    container_name: kafka-connect
    depends_on:
      - kafka
    ports:
      - "8083:8083"
    environment:
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses
      BOOTSTRAP_SERVERS: kafka:29092
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
    networks:
      - kafka-network
      - app-network
    healthcheck:
      test: curl -f http://localhost:8083/connectors || exit 1
      interval: 30s
      timeout: 10s
      retries: 5

  debezium-init:
    image: curlimages/curl
    container_name: debezium-init
    depends_on:
      - kafka-connect
    networks:
      - kafka-network
      - app-network
    restart: on-failure
    command: >
      sh -c '
      echo "Waiting for Kafka Connect to start..."
      while [[ "$$(curl -s -o /dev/null -w "%{http_code}" http://kafka-connect:8083/connectors)" != "200" ]]; do 
        echo "Waiting for Kafka Connect..."
        sleep 5
      done

      echo "Setting up MySQL source connector..."
      curl -X POST -H "Content-Type: application/json" --data @- http://kafka-connect:8083/connectors << EOF
      {
        "name": "mysql-connector",
        "config": {
          "connector.class": "io.debezium.connector.mysql.MySqlConnector",
          "tasks.max": "1",
          "database.hostname": "mysql",
          "database.port": "3306",
          "database.user": "myuser",
          "database.password": "mypassword",
          "database.server.id": "1",
          "database.server.name": "mysql",
          "database.include.list": "ground_write_db",
          "database.history.kafka.bootstrap.servers": "kafka:29092",
          "database.history.kafka.topic": "schema-changes.ground_write_db",
          "include.schema.changes": "true",
          "time.precision.mode": "connect"
        }
      }
      EOF

      echo "Setting up MongoDB sink connector..."
      curl -X POST -H "Content-Type: application/json" --data @- http://kafka-connect:8083/connectors << EOF
      {
        "name": "mongodb-sink",
        "config": {
          "connector.class": "com.mongodb.kafka.connect.MongoSinkConnector",
          "tasks.max": "1",
          "topics.regex": "mysql\\.ground_write_db\\.(.*)",
          "connection.uri": "mongodb://root:root@mongodb:27017/ground_read_db?authSource=admin",
          "database": "ground_read_db",
          "collection": "${topic.substring(topic.lastIndexOf(\".\") + 1)}",
          "key.converter": "org.apache.kafka.connect.json.JsonConverter",
          "key.converter.schemas.enable": "false",
          "value.converter": "org.apache.kafka.connect.json.JsonConverter",
          "value.converter.schemas.enable": "false",
          "document.id.strategy": "com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy",
          "transforms": "unwrap",
          "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
          "transforms.unwrap.drop.tombstones": "false",
          "transforms.unwrap.delete.handling.mode": "drop",
          "transforms.unwrap.add.fields": "op,db,table,source.ts_ms,source.ts_ms=ts_ms,source.file,source.pos,source.snapshot",
          "transforms.unwrap.add.fields.prefix": "cdc_"
        }
      }
      EOF
      '

networks:
  kafka-network:
    driver: bridge
  app-network:
    external: true

volumes:
  zookeeper-data:
  zookeeper-log:
  kafka-data: